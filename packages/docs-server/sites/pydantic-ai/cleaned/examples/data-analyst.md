[ Skip to content ](#data-analyst)
# Data Analyst
Sometimes in an agent workflow, the agent does not need to know the exact tool output, but still needs to process the tool output in some ways. This is especially common in data analytics: the agent needs to know that the result of a query tool is a `DataFrame` with certain named columns, but not necessarily the content of every single row.
With Pydantic AI, you can use a [dependencies object](../../dependencies/) to store the result from one tool and use it in another tool.
In this example, we'll build an agent that analyzes the [Rotten Tomatoes movie review dataset from Cornell](https://huggingface.co/datasets/cornell-movie-review-data/rotten_tomatoes).
Demonstrates:
 * [agent dependencies](../../dependencies/)
## Running the Example
With [dependencies installed and environment variables set](../setup/#usage), run:
pipuv
```
python
```
```
uv
```
Output (debug):
> Based on my analysis of the Cornell Movie Review dataset (rotten_tomatoes), there are **4,265 negative comments** in the training split. These are the reviews labeled as 'neg' (represented by 0 in the dataset).
## Example Code
[data_analyst.py](https://github.com/pydantic/pydantic-ai/blob/main/examples/pydantic_ai_examples/data_analyst.py)```
fromdataclassesimport dataclass, field
importdatasets
importduckdb
importpandasaspd
frompydantic_aiimport Agent, ModelRetry, RunContext
@dataclass
classAnalystAgentDeps:
 output: dict[str, pd.DataFrame] = field(default_factory=dict)
 defstore(self, value: pd.DataFrame) -> str:
"""Store the output in deps and return the reference such as Out[1] to be used by the LLM."""
 ref = f'Out[{len(self.output)+1}]'
 self.output[ref] = value
 return ref
 defget(self, ref: str) -> pd.DataFrame:
 if ref not in self.output:
 raise ModelRetry(
 f'Error: {ref} is not a valid variable reference. Check the previous messages and try again.'
 )
 return self.output[ref]
analyst_agent = Agent(
 'openai:gpt-5',
 deps_type=AnalystAgentDeps,
 instructions='You are a data analyst and your job is to analyze the data according to the user request.',
)
@analyst_agent.tool
defload_dataset(
 ctx: RunContext[AnalystAgentDeps],
 path: str,
 split: str = 'train',
) -> str:
"""Load the `split` of dataset `dataset_name` from huggingface.
 Args:
 ctx: Pydantic AI agent RunContext
 path: name of the dataset in the form of `<user_name>/<dataset_name>`
 split: load the split of the dataset (default: "train")
 """
 # begin load data from hf
 builder = datasets.load_dataset_builder(path) # pyright: ignore[reportUnknownMemberType]
 splits: dict[str, datasets.SplitInfo] = builder.info.splits or {} # pyright: ignore[reportUnknownMemberType]
 if split not in splits:
 raise ModelRetry(
 f'{split} is not valid for dataset {path}. Valid splits are {",".join(splits.keys())}'
 )
 builder.download_and_prepare() # pyright: ignore[reportUnknownMemberType]
 dataset = builder.as_dataset(split=split)
 assert isinstance(dataset, datasets.Dataset)
 dataframe = dataset.to_pandas()
 assert isinstance(dataframe, pd.DataFrame)
 # end load data from hf
 # store the dataframe in the deps and get a ref like "Out[1]"
 ref = ctx.deps.store(dataframe)
 # construct a summary of the loaded dataset
 output = [
 f'Loaded the dataset as `{ref}`.',
 f'Description: {dataset.info.description}'
 if dataset.info.description
 else None,
 f'Features: {dataset.info.features!r}' if dataset.info.features else None,
 ]
 return '\n'.join(filter(None, output))
@analyst_agent.tool
defrun_duckdb(ctx: RunContext[AnalystAgentDeps], dataset: str, sql: str) -> str:
"""Run DuckDB SQL query on the DataFrame.
 Note that the virtual table name used in DuckDB SQL must be `dataset`.
 Args:
 ctx: Pydantic AI agent RunContext
 dataset: reference string to the DataFrame
 sql: the query to be executed using DuckDB
 """
 data = ctx.deps.get(dataset)
 result = duckdb.query_df(df=data, virtual_table_name='dataset', sql_query=sql)
 # pass the result as ref (because DuckDB SQL can select many rows, creating another huge dataframe)
 ref = ctx.deps.store(result.df()) # pyright: ignore[reportUnknownMemberType]
 return f'Executed SQL, result is `{ref}`'
@analyst_agent.tool
defdisplay(ctx: RunContext[AnalystAgentDeps], name: str) -> str:
"""Display at most 5 rows of the dataframe."""
 dataset = ctx.deps.get(name)
 return dataset.head().to_string() # pyright: ignore[reportUnknownMemberType]
if __name__ == '__main__':
 deps = AnalystAgentDeps()
 result = analyst_agent.run_sync(
 user_prompt='Count how many negative comments are there in the dataset `cornell-movie-review-data/rotten_tomatoes`',
 deps=deps,
 )
 print(result.output)
```
## Appendix
### Choosing a Model
This example requires using a model that understands DuckDB SQL. You can check with `clai`:
```
>do# DuckDB SQL
Yes,in-processinfor(Online)forhelp
```