`/`
[Product docs](/docs/home)[Guides](/docs/guides)[SDKs](/docs/sdk)[Integrations](/docs/integrations)[API docs](/docs/api)[Tutorials](/docs/tutorials)[Flagship Blog](/docs/blog)
 * Getting started
 * [Overview](/docs/home)
 * [Launch Insights](/docs/home/getting-started/launch-insights)
 * [LaunchDarkly architecture](/docs/home/getting-started/architecture)
 * [LaunchDarkly vocabulary](/docs/home/getting-started/vocabulary)
 * Feature flags and AI Configs
 * [Create flags](/docs/home/flags/create)
 * [Target with flags](/docs/home/flags/target)
 * [Flag templates](/docs/home/flags/templates)
 * [Manage flags](/docs/home/flags/manage)
 * [Code references](/docs/home/flags/code-references)
 * [AI Configs](/docs/home/ai-configs)
 * [Contexts](/docs/home/flags/contexts)
 * [Segments](/docs/home/flags/segments)
 * Releases
 * [Releasing features with LaunchDarkly](/docs/home/releases/releasing)
 * [Release policies](/docs/home/releases/release-policies)
 * [Percentage rollouts](/docs/home/releases/percentage-rollouts)
 * [Progressive rollouts](/docs/home/releases/progressive-rollouts)
 * [Guarded rollouts](/docs/home/releases/guarded-rollouts)
 * [Feature monitoring](/docs/home/releases/feature-monitoring)
 * [Release pipelines](/docs/home/releases/release-pipelines)
 * [Engineering insights](/docs/home/releases/eng-insights)
 * [Release management tools](/docs/home/releases/release-management)
 * [Applications and app versions](/docs/home/releases/apps-and-app-versions)
 * [Change history](/docs/home/releases/change-history)
 * Observability
 * [Observability](/docs/home/observability)
 * [Session replay](/docs/home/observability/session-replay)
 * [Error monitoring](/docs/home/observability/errors)
 * [Logs](/docs/home/observability/logs)
 * [Traces](/docs/home/observability/traces)
 * [LLM observability](/docs/home/observability/llm-observability)
 * [Alerts](/docs/home/observability/alerts)
 * [Dashboards](/docs/home/observability/dashboards)
 * [Search specification](/docs/home/observability/search)
 * [Observability settings](/docs/home/observability/settings)
 * [Vega](/docs/home/observability/vega)
 * Product analytics
 * [Product analytics](/docs/home/product-analytics)
 * [Setting up product analytics](/docs/home/product-analytics/setup)
 * [Using product analytics charts](/docs/home/product-analytics/chart)
 * Experimentation
 * [Experimentation](/docs/home/experimentation)
 * [Creating experiments](/docs/home/experimentation/create)
 * [Managing experiments](/docs/home/experimentation/manage)
 * [Analyzing experiments](/docs/home/experimentation/analyze)
 * [Experimentation and metric events](/docs/home/experimentation/events)
 * [Multi-armed bandits](/docs/home/multi-armed-bandits)
 * [Holdouts](/docs/home/holdouts)
 * Metrics
 * [Metrics](/docs/home/metrics)
 * [Metric groups](/docs/home/metrics/metric-groups)
 * [Autogenerated metrics](/docs/home/metrics/autogen-metrics)
 * [Metric impact](/docs/home/metrics/metric-impact)
 * [Metric events](/docs/home/metrics/metric-events)
 * Warehouse native
 * [Warehouse native Experimentation](/docs/home/warehouse-native)
 * [Warehouse native metrics](/docs/home/warehouse-native/metrics)
 * [Creating warehouse native experiments](/docs/home/warehouse-native/creating)
 * Infrastructure
 * [Connect apps and services to LaunchDarkly](/docs/home/infrastructure/apps)
 * [LaunchDarkly in China and Pakistan](/docs/home/infrastructure/china)
 * [LaunchDarkly in the European Union (EU)](/docs/home/infrastructure/eu)
 * [LaunchDarkly in federal environments](/docs/home/infrastructure/federal)
 * [Public IP list](/docs/home/infrastructure/ip-list)
 * Your account
 * [Projects](/docs/home/account/project)
 * [Views](/docs/home/account/views)
 * [Environments](/docs/home/account/environment)
 * [Tags](/docs/home/account/tags)
 * [Teams](/docs/home/account/teams)
 * [Members](/docs/home/account/members)
 * [Roles](/docs/home/account/roles)
 * [Account security](/docs/home/account/secure)
 * [Billing and usage](/docs/home/account/billing)
 * [Changelog](/docs/home/changelog)
[Sign in](/)[Sign up](https://app.launchdarkly.com/signup)
On this page
 * [Overview](#overview)
 * [Summary](#summary)
 * [Cumulative exposures](#cumulative-exposures)
 * [Cumulative results](#cumulative-results)
 * [Leading variation](#leading-variation)
 * [Probability density](#probability-density)
 * [Probability to be best](#probability-to-be-best)
 * [Binary conversion metrics](#binary-conversion-metrics)
 * [Conversion rate](#conversion-rate)
 * [Conversions](#conversions)
 * [Total exposures](#total-exposures)
 * [Count conversion and numeric metrics](#count-conversion-and-numeric-metrics)
 * [Posterior mean](#posterior-mean)
 * [Total value](#total-value)
 * [Total exposures](#total-exposures-1)
## Overview
This topic explains how to read the results of a multi-armed bandit (MAB). MABs automatically shift traffic to the leading variation over time, so you do not need to actively monitor a MAB, and you do not need to manually ship the leading variation. However, you can still use the **Results** tab to view the performance of each variation, and understand how the MAB is reallocating traffic.
You can run a MAB indefinitely, allowing it to reallocate traffic as needed. If you don’t want to run a MAB indefinitely, we recommend that you stop it when a single variation’s probability to be best reaches 99% or higher.
If you are running a MAB on a time-boxed feature, such as a holiday promotion, then you can stop the MAB iteration when the promotion is over.
## Summary
The “Summary” section displays the MAB’s optimization goal and key takeaways.
## Cumulative exposures
The “Cumulative exposures” section displays how many contexts have encountered each variation over time. Hover on the chart to display a breakdown of how many contexts encountered each variation on a specific date and time.
![A multi-armed bandit cumulative exposures chart with the exposures for a specific date displayed.](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/57c2bfcb10333afd40e10d40feec40cfa75e79a8e38c55f29b1ba04cd681818f/assets/images/__LD_UI_no_test/mab-cumulative-exposures.png)
A multi-armed bandit cumulative exposures chart with the exposures for a specific date displayed.
## Cumulative results
The “Cumulative results” chart displays the leading variation, and, depending on the metric type, columns with information about probability to be best, conversion rate, conversions, mean, and exposures.
### Leading variation
The leading variation is the treatment that currently has the highest probability to be best. As the MAB runs, it will reallocate traffic to the leading variation at the frequency you specified when you created it.
The current leading variation is indicated on the “Cumulative results” chart:
![A multi-armed bandit cumulative results chart.](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/a94a0928084e68a70187a4a200100a80d310e816daa90aa85c2ef9377e2117a2/assets/images/__LD_UI_no_test/mab-cumulative-results.png)
A multi-armed bandit cumulative results chart.
### Probability density
The probability density chart displays the distribution of the results for the metric. Click **Show probability density chart** to display the chart, and **Hide probability density chart** to hide it.
![A multi-armed bandit probability density chart.](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/8f86ff0dcb16e36d6b5b260c80b3ef2b2881dbcb68cfb81639b27707301d7769/assets/images/__LD_UI_no_test/mab-density-chart.png)
A multi-armed bandit probability density chart.
The horizontal x-axis displays the unit of the metric included in the experiment. For example, if the metric is measuring revenue, the unit might be dollars, or if the metric is measuring website latency, the unit might be milliseconds.
If the unit you’re measuring on the x-axis is something you want to increase, such as revenue, account sign ups, and so on, then the farther to the right the curve is, the better. The variation with the curve farthest to the right means the unit the metric is measuring is highest for that variation.
If the unit you’re measuring on the x-axis is something you want to decrease, such as website latency, then the farther to the left the curve is, the better. The variation with the curve farthest to the left means the unit the metric is measuring is lowest for that variation.
How wide a curve is on the x-axis determines the credible interval. Narrower curves mean the results of the variation fall within a smaller range of values, so you can be more confident in the likely results of that variation’s performance.
The vertical y-axis measures probability. You can determine how probable it is that the metric will equal the number on the x-axis by how high the curve is.
### Probability to be best
The probability to be best for a variation is the likelihood that it outperforms all other variations for a specific metric. For MABs, the variation with the highest probability to be best is considered the leading variation.
Additional columns in the “Cumulative results” chart display depending on the metric type you used in the MAB. Expand the sections below to view information for different metric types.
### Binary conversion metrics
Binary conversion metrics include:
 * [Custom conversion binary](/docs/home/metrics/custom) metrics
 * [Clicked or tapped](/docs/home/metrics/click) metrics using the **Occurrence** option
 * [Page viewed](/docs/home/metrics/pageview) metrics using the **Occurrence** option
###### Expand Binary conversion metrics
#### Conversion rate
The value for each unit in a binary conversion metric can be either 1 or 0. A value of 1 means the conversion occurred, such as a user viewing a web page, or submitting a form. A value of 0 means no conversion occurred.
The conversion rate column displays the percentage of units with at least one conversion that you should expect in this experiment, based on the data collected so far. For example, the percentage of users you can expect to click at least once.
#### Conversions
The conversions column displays the total number of users or other contexts that had at least one conversion.
#### Total exposures
The total exposures column displays the total number of contexts that encountered the metric as part of the MAB.
### Count conversion and numeric metrics
Count conversion and numeric metrics include:
 * [Custom conversion count](/docs/home/metrics/custom-count) metrics
 * [Numeric](/docs/home/metrics/custom-numeric) metrics
 * [Clicked or tapped](/docs/home/metrics/click) metrics using the **Count** option
 * [Page viewed](/docs/home/metrics/pageview) metrics using the **Count** option
###### Expand Count conversion and numeric metrics
#### Posterior mean
The posterior mean is the variation’s average numeric value that you should expect in this experiment, based on the data collected so far.
All of the data in the results table are based on a posterior distribution, which is the combination of the collected data and our prior beliefs about that data. To learn more about posterior distributions, read [Frequentist and Bayesian modeling](/docs/guides/experimentation/bayesian-frequentist#bayesian-and-frequentist-modeling).
LaunchDarkly automatically performs checks on the results data, to make sure that actual context traffic matches the allocation you set. To learn more, read [Understanding sample ratios](/docs/guides/statistical-methodology/sample-ratios).
#### Total value
The total value is the sum total of all the numbers returned by a numeric metric.
#### Total exposures
The total exposures column displays the total number of contexts that encountered the metric as part of the MAB.
[![Logo](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/a8964c2c365fb94c416a0e31ff873d21ce0c3cbf40142e7e66cce5ae08a093af/assets/logo-dark.svg)![Logo](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/a8964c2c365fb94c416a0e31ff873d21ce0c3cbf40142e7e66cce5ae08a093af/assets/logo-dark.svg)](/docs/home)
LaunchDarkly docs
LaunchDarkly docs
LaunchDarkly docs
LaunchDarkly docs