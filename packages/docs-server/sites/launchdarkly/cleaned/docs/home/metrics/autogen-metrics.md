`/`
[Product docs](/docs/home)[Guides](/docs/guides)[SDKs](/docs/sdk)[Integrations](/docs/integrations)[API docs](/docs/api)[Tutorials](/docs/tutorials)[Flagship Blog](/docs/blog)
 * Getting started
 * [Overview](/docs/home)
 * [Launch Insights](/docs/home/getting-started/launch-insights)
 * [LaunchDarkly architecture](/docs/home/getting-started/architecture)
 * [LaunchDarkly vocabulary](/docs/home/getting-started/vocabulary)
 * Feature flags and AI Configs
 * [Create flags](/docs/home/flags/create)
 * [Target with flags](/docs/home/flags/target)
 * [Flag templates](/docs/home/flags/templates)
 * [Manage flags](/docs/home/flags/manage)
 * [Code references](/docs/home/flags/code-references)
 * [AI Configs](/docs/home/ai-configs)
 * [Contexts](/docs/home/flags/contexts)
 * [Segments](/docs/home/flags/segments)
 * Releases
 * [Releasing features with LaunchDarkly](/docs/home/releases/releasing)
 * [Release policies](/docs/home/releases/release-policies)
 * [Percentage rollouts](/docs/home/releases/percentage-rollouts)
 * [Progressive rollouts](/docs/home/releases/progressive-rollouts)
 * [Guarded rollouts](/docs/home/releases/guarded-rollouts)
 * [Feature monitoring](/docs/home/releases/feature-monitoring)
 * [Release pipelines](/docs/home/releases/release-pipelines)
 * [Engineering insights](/docs/home/releases/eng-insights)
 * [Release management tools](/docs/home/releases/release-management)
 * [Applications and app versions](/docs/home/releases/apps-and-app-versions)
 * [Change history](/docs/home/releases/change-history)
 * Observability
 * [Observability](/docs/home/observability)
 * [Session replay](/docs/home/observability/session-replay)
 * [Error monitoring](/docs/home/observability/errors)
 * [Logs](/docs/home/observability/logs)
 * [Traces](/docs/home/observability/traces)
 * [LLM observability](/docs/home/observability/llm-observability)
 * [Alerts](/docs/home/observability/alerts)
 * [Dashboards](/docs/home/observability/dashboards)
 * [Search specification](/docs/home/observability/search)
 * [Observability settings](/docs/home/observability/settings)
 * [Vega](/docs/home/observability/vega)
 * Product analytics
 * [Product analytics](/docs/home/product-analytics)
 * [Setting up product analytics](/docs/home/product-analytics/setup)
 * [Using product analytics charts](/docs/home/product-analytics/chart)
 * Experimentation
 * [Experimentation](/docs/home/experimentation)
 * [Creating experiments](/docs/home/experimentation/create)
 * [Managing experiments](/docs/home/experimentation/manage)
 * [Analyzing experiments](/docs/home/experimentation/analyze)
 * [Experimentation and metric events](/docs/home/experimentation/events)
 * [Multi-armed bandits](/docs/home/multi-armed-bandits)
 * [Holdouts](/docs/home/holdouts)
 * Metrics
 * [Metrics](/docs/home/metrics)
 * [Metric groups](/docs/home/metrics/metric-groups)
 * [Autogenerated metrics](/docs/home/metrics/autogen-metrics)
 * [Metric impact](/docs/home/metrics/metric-impact)
 * [Metric events](/docs/home/metrics/metric-events)
 * Warehouse native
 * [Warehouse native Experimentation](/docs/home/warehouse-native)
 * [Warehouse native metrics](/docs/home/warehouse-native/metrics)
 * [Creating warehouse native experiments](/docs/home/warehouse-native/creating)
 * Infrastructure
 * [Connect apps and services to LaunchDarkly](/docs/home/infrastructure/apps)
 * [LaunchDarkly in China and Pakistan](/docs/home/infrastructure/china)
 * [LaunchDarkly in the European Union (EU)](/docs/home/infrastructure/eu)
 * [LaunchDarkly in federal environments](/docs/home/infrastructure/federal)
 * [Public IP list](/docs/home/infrastructure/ip-list)
 * Your account
 * [Projects](/docs/home/account/project)
 * [Views](/docs/home/account/views)
 * [Environments](/docs/home/account/environment)
 * [Tags](/docs/home/account/tags)
 * [Teams](/docs/home/account/teams)
 * [Members](/docs/home/account/members)
 * [Roles](/docs/home/account/roles)
 * [Account security](/docs/home/account/secure)
 * [Billing and usage](/docs/home/account/billing)
 * [Changelog](/docs/home/changelog)
[Sign in](/)[Sign up](https://app.launchdarkly.com/signup)
On this page
 * [Overview](#overview)
 * [Metric events](#metric-events)
 * [Randomization units for autogenerated metrics](#randomization-units-for-autogenerated-metrics)
 * [Metrics autogenerated from AI SDK events](#metrics-autogenerated-from-ai-sdk-events)
 * [Metrics autogenerated from observability events](#metrics-autogenerated-from-observability-events)
 * [Metrics autogenerated from OpenTelemetry data](#metrics-autogenerated-from-opentelemetry-data)
## Overview
This topic explains the metrics LaunchDarkly automatically generates from SDK events and how you can use them to monitor the health of your applications.
## Metric events
An “event” happens when someone takes an action in your app, such as clicking on a button, or when a system takes an action, such as loading a page. Your SDKs send these metric events to LaunchDarkly, where, for certain event kinds, LaunchDarkly can automatically create metrics from those events. You can use these metrics with [experiments](/docs/home/experimentation) and [guarded rollouts](/docs/home/releases/guarded-rollouts) to track how your flag changes affect your customers’ behavior.
LaunchDarkly autogenerates metrics from events that are sent:
 * from [AI SDKs](/docs/sdk/ai) used in conjunction with [AI Configs](/docs/home/ai-configs)
 * during document load, for browser apps, if you are using the [Observability SDKs](/docs/sdk/observability)
 * as part of OpenTelemetry traces using the [OpenTelemetry](/docs/sdk/features/opentelemetry-server-side) feature for server-side SDKs
Autogenerated metrics are marked on the [**Metrics** list](/docs/home/metrics) with an `autogenerated` [tag](/docs/home/account/tags). You can view the events that autogenerated these metrics from the **Metrics** list by clicking **View** , then **Events**.
To learn more, read [Metric events](/docs/home/metrics/metric-events) and [Metric analysis](/docs/home/metrics/metric-analysis).
## Randomization units for autogenerated metrics
LaunchDarkly sets the [randomization unit](/docs/home/experimentation/randomization) for autogenerated metrics to your account’s default context kind for experiments. For most accounts, the default context kind for experiments is `user`. However, you may have updated your default context kind to `account`, `device`, or some other context kind you use in experiments most often. To learn how to change the default context kind for experiments, read [Randomization units other than “user”](/docs/home/experimentation/randomization#randomization-units-other-than-user).
All autogenerated metrics are designed to work with a randomization unit of either `user` or `request`. Depending on your account’s default context kind for experiments, you may need to manually update the randomization unit for autogenerated metrics as needed. The recommended randomization units for each autogenerated metric are listed in the tables below. To learn how to manually update the randomization unit for a metric, read [Edit metrics](/docs/home/metrics/create-metrics#edit-metrics).
To learn more, read [Randomization units](/docs/home/experimentation/randomization).
## Metrics autogenerated from AI SDK events
An [AI Config](/docs/home/ai-configs) is a resource that you create in LaunchDarkly and then use to customize, test, and roll out new large language models (LLMs) within your generative AI applications. As soon as you start using AI Configs in your application, you can [track how your AI model generation is performing](/docs/sdk/features/ai-metrics), and your AI SDKs begin sending events to LaunchDarkly.
AI SDK events are prefixed with `$ld:ai` and LaunchDarkly automatically generates metrics from these events.
Some events generate multiple metrics that measure different aspects of the same event. For example, the `$ld:ai:feedback:user:positive` event generates a metric that measures the average number of positive feedback events per user, and a metric that measures the percentage of users that generated positive feedback.
The following expandable sections explain the metrics that LaunchDarkly autogenerates from AI SDK events:
Positive AI feedback count `$ld:ai:feedback:user:positive`
**Metric kind** : Custom conversion count
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Count
 * Unit aggregation method: Sum
 * Analysis method: Average
 * Success criterion: Higher is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Average number of positive feedback events per context
**Example usage** : Running an experiment to find out which variation causes more users to click “thumbs up”
Positive AI feedback rate `$ld:ai:feedback:user:positive`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Higher is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Percentage of contexts that generated positive AI feedback
**Example usage** : Running a guarded rollout to make sure there is a positive feedback ratio throughout the rollout
Negative AI feedback count `$ld:ai:feedback:user:negative`
**Metric kind** : Custom conversion count
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Count
 * Unit aggregation method: Sum
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Average number of negative feedback events per context
**Example usage** : Running an experiment to find out which variation causes more users to click “thumbs down”
Negative AI feedback rate `$ld:ai:feedback:user:negative`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Percentage of contexts that generated negative AI feedback
**Example usage** : Running an experiment to find out which variation causes more users to click “thumbs down”
Average input tokens per AI completion `$ld:ai:tokens:input`
**Metric kind** : Numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : For example, for a chatbot, this might indicate user engagement
**Example usage** : Running an experiment to find out which variation results in fewer input tokens, reducing cost
Average output tokens per AI completion `$ld:ai:tokens:output`
**Metric kind** : Numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : Indicator of cost, when charged by token usage
**Example usage** : Running an experiment to find out which variation results in fewer output tokens, reducing cost
Average total tokens per AI completion `$ld:ai:tokens:total`
**Metric kind** : Numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : Indicator of cost, when charged by token usage
**Example usage** : Running an experiment to find out which variation results in fewer total tokens, reducing cost
Average AI completion time `$ld:ai:duration:total`
**Metric kind** : Numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : Time required for LLM to finish a completion
**Example usage** : Running an experiment to find out which variation results in faster user completion, improving engagement
AI completion success count `$ld:ai:generation:success`
**Metric kind** : Custom conversion count
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Count
 * Unit aggregation method: Sum
 * Analysis method: Average
 * Success criterion: Higher is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Counter for successful LLM completion requests
**Example usage** : Running an experiment to find out which variation results in more user completion requests (“chattiness”), improving engagement
AI completion error count `$ld:ai:generation:error`
**Metric kind** : Custom conversion count
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Counter for erroneous LLM completion requests
**Example usage** : Running a guarded rollout to make sure the change doesn’t result in a higher error rate
AI completion error count `$ld:ai:generation:error`
**Metric kind** : Custom
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Counter for erroneous LLM completion requests
**Example usage** : Running a guarded rollout to make sure the change doesn’t result in a higher error rate
AI completion error count `$ld:ai:generation:error`
**Metric kind** : Custom
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Count
 * Unit aggregation method: Sum
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Counter for erroneous LLM completion requests
**Example usage** : Running a guarded rollout to make sure the change doesn’t result in a higher number of errors
Average time to first token for AI requests `$ld:ai:tokens:ttf`
**Metric kind** : Numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : Time required for LLM to generate first token
**Example usage** : Running a guarded rollout to make sure the change doesn’t result in longer token generation times
As an example, the autogenerated metric in the first expandable section above tracks the average number of positive feedback ratings per user.
Here is what the metric setup looks like in the LaunchDarkly user interface:
![An autogenerated metric.](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/195395a3cf3f2960726f7235e1bfee07ce60030ab728cef11cace279eeb9c65f/assets/images/__toPlaywright_newIA/autogen-metric.png)
An autogenerated metric.
## Metrics autogenerated from observability events
The LaunchDarkly [observability SDKs](/docs/sdk/observability) provide error monitoring and metric collection for errors, web vitals, and document loading in your browser application. The functionality is in separate plugins, which you enable in the initialization options for the LaunchDarkly SDK. The observability plugins collect and send data to LaunchDarkly, where you can review metrics, events, and errors from your application.
The observability events are prefixed with `$ld:telemetry` and LaunchDarkly automatically generates metrics from these events.
These expandable sections explain the metrics that LaunchDarkly autogenerates from events recorded by the observability plugins for LaunchDarkly browser SDKs:
Average Cumulative Layout Shift (CLS) per context (LaunchDarkly) `$ld:telemetry:metric:cls`
**Metric kind** : Custom numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the average largest burst per context of layout shift scores for every unexpected layout shift that occurs during the entire lifecycle of a page.
**Example usage** : Observing the latency of interactions an end user makes with your application
P95 Cumulative Layout Shift (CLS) per context (LaunchDarkly) `$ld:telemetry:metric:cls`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 95th percentile largest burst per context of layout shift scores for every unexpected layout shift that occurs during the entire lifecycle of a page.
**Example usage** : Observing the latency of interactions an end user makes with your application
P99 Cumulative Layout Shift (CLS) per context (LaunchDarkly) `$ld:telemetry:metric:cls`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 99th percentile largest burst per context of layout shift scores for every unexpected layout shift that occurs during the entire lifecycle of a page.
**Example usage** : Observing the latency of interactions an end user makes with your application
Average Document Load Latency per context (LaunchDarkly) `$ld:telemetry:metric:document_load`
**Metric kind** : Custom numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the average DOM load duration in milliseconds per context
**Example usage** : Observing the latency of interactions an end user makes with your application
P95 Document Load Latency per context (LaunchDarkly) `$ld:telemetry:metric:document_load`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 95th percentile DOM load duration in milliseconds per context
**Example usage** : Observing the latency of interactions an end user makes with your application
P99 Document Load Latency per context (LaunchDarkly) `$ld:telemetry:metric:document_load`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 99th percentile DOM load duration in milliseconds per context
**Example usage** : Observing the latency of interactions an end user makes with your application
User error rate (LaunchDarkly) `$ld:telemetry:error`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Measures the percentage of contexts that encountered an error at least once. This metric is autogenerated by an initial `$ld:telemetry:session:init` event and populated by subsequent `$ld:telemetry:error` events. This means you can use the metric even if your app has not yet generated any errors.
**Example usage** : Running a guarded rollout to make sure the error change doesn’t result in a higher error rate
Average First Contentful Paint (FCP) per context (LaunchDarkly) `$ld:telemetry:metric:fcp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the average time in milliseconds per context between first navigation to a page and when any part of the page’s content is rendered.
**Example usage** : Observing the latency of interactions an end user makes with your application
P95 First Contentful Paint (FCP) per context (LaunchDarkly) `$ld:telemetry:metric:fcp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 95th percentile time in milliseconds per context between first navigation to a page and when any part of the page’s content is rendered.
**Example usage** : Observing the latency of interactions an end user makes with your application
P99 First Contentful Paint (FCP) per context (LaunchDarkly) `$ld:telemetry:metric:fcp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 99th percentile time in milliseconds per context between first navigation to a page and when any part of the page’s content is rendered.
**Example usage** : Observing the latency of interactions an end user makes with your application
Average First Input Delay (FID) per context (LaunchDarkly) `$ld:telemetry:metric:fid`
**Metric kind** : Custom numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the average time in milliseconds per context between a user’s first interaction (click, tap, or key press) and the time when the browser starts processing event handlers in response to that interaction.
**Example usage** : Observing the latency of interactions an end user makes with your application
P95 First Input Delay (FID) per context (LaunchDarkly) `$ld:telemetry:metric:fid`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 95th percentile time, in milliseconds per context, between a user’s first interaction (click, tap, or key press) and the time when the browser starts processing event handlers in response to that interaction.
**Example usage** : Observing the latency of interactions an end user makes with your application
P99 First Input Delay (FID) per context (LaunchDarkly) `$ld:telemetry:metric:fid`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 99th percentile time, in milliseconds per context, between a user’s first interaction (click, tap, or key press) and the time when the browser starts processing event handlers in response to that interaction.
**Example usage** : Observing the latency of interactions an end user makes with your application
Average Interaction to Next Paint (INP) per context (LaunchDarkly) `$ld:telemetry:metric:inp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the average response time in milliseconds per context of all click, tap, and keyboard interactions during the lifespan of a visit to a page.
**Example usage** : Observing the latency of interactions an end user makes with your application
P95 Interaction to Next Paint (INP) per context (LaunchDarkly) `$ld:telemetry:metric:inp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 95th percentile response time in milliseconds per context of all click, tap, and keyboard interactions during the lifespan of a visit to a page.
**Example usage** : Observing the latency of interactions an end user makes with your application
P99 Interaction to Next Paint (INP) per context (LaunchDarkly) `$ld:telemetry:metric:inp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 99th percentile response time in milliseconds per context of all click, tap, and keyboard interactions during the lifespan of a visit to a page.
**Example usage** : Observing the latency of interactions an end user makes with your application
Average Largest Contentful Paint (LCP) per context (LaunchDarkly) `$ld:telemetry:metric:lcp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the average time in milliseconds per context to render the largest image, text block, or video visible when first navigating to a page
**Example usage** : Observing the latency of interactions an end user makes with your application
P95 Largest Contentful Paint (LCP) per context (LaunchDarkly) `$ld:telemetry:metric:lcp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 95th percentile time in milliseconds per context to render the largest image, text block, or video visible when first navigating to a page
**Example usage** : Observing the latency of interactions an end user makes with your application
P99 Largest Contentful Paint (LCP) per context (LaunchDarkly) `$ld:telemetry:metric:lcp`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 99th percentile time in milliseconds per context to render the largest image, text block, or video visible when first navigating to a page
**Example usage** : Observing the latency of interactions an end user makes with your application
Average Time to First Byte (TTFB) per context (LaunchDarkly) `$ld:telemetry:metric:ttfb`
**Metric kind** : Custom numeric
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the average time in milliseconds per context between the request for a resource and when the first byte of a response begins to arrive.
**Example usage** : Observing the latency of interactions an end user makes with your application
P95 Time to First Byte (TTFB) per context (LaunchDarkly) `$ld:telemetry:metric:ttfb`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 95th percentile time in milliseconds per context between the request for a resource and when the first byte of a response begins to arrive.
**Example usage** : Observing the latency of interactions an end user makes with your application
P99 Time to First Byte (TTFB) per context (LaunchDarkly) `$ld:telemetry:metric:ttfb`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events from the analysis
**Description** : Measures the 99th percentile time in milliseconds per context between the request for a resource and when the first byte of a response begins to arrive.
**Example usage** : Observing the latency of interactions an end user makes with your application
## Metrics autogenerated from OpenTelemetry data
LaunchDarkly’s SDKs support instrumentation for OpenTelemetry traces. Traces provide an overview of how your application handles requests. For example, traces may show that a particular feature flag was evaluated for a particular context as part of a given HTTP request. When LaunchDarkly receives OpenTelemetry trace data, it processes and converts this data into events that LaunchDarkly metrics track over time.
There are two types of events that LaunchDarkly creates from OpenTelemetry traces: route-specific events and global events. Route-specific events are useful when you are experimenting with a change that is known to impact a small subset of your server’s HTTP routes. Global events are useful when you believe your change may impact all routes, or when you are not sure of the impact of your change.
To learn more, read [OpenTelemetry for server-side SDKs](/docs/sdk/features/opentelemetry-server-side).
OpenTelemetry events are prefixed with `otel`. LaunchDarkly automatically creates the following metrics from the events that LaunchDarkly produces from your OpenTelemetry trace data. This trace data includes the feature flag and the context for which you evaluated the flag. You can also create these metrics manually if you wish.
These expandable sections explain the metrics that LaunchDarkly autogenerates from OpenTelemetry traces:
User HTTP error rate (OpenTelemetry) `otel.http.error`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Measures the percentage of users that encountered an error inside HTTP spans at least once, as reported by OpenTelemetry. Useful when running a guarded rollout.
Per-route HTTP request errors `http.error;method={http.request.method};route={http.route}`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Examples** :
 * `http.error;method=GET;route=/api/v2/flags`
 * `http.error;method=PATCH;route=/api/v2/flags/{id}`
User HTTP 5XX response rate (OpenTelemetry) `otel.http.5XX`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Measures the percentage of users that encountered an HTTP 5XX response at least once, as reported by OpenTelemetry. Useful when running a guarded rollout.
Per-route HTTP 5XXs (OpenTelemetry) `http.5XX;method={http.request.method};route={http.route}`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Examples** :
 * `http.5XX;method=GET;route=/api/v2/flags`
 * `http.5XX;method=PATCH;route=/api/v2/flags/{id}`
User non-HTTP exception rate (OpenTelemetry) `otel.exception`
**Metric kind** : Custom conversion binary
**Suggested randomization unit** : User
**Definition** :
 * Measurement method: Occurrence
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Include units that did not send any events and set their value to 0
**Description** : Measures the percentage of users that encountered an exception outside of HTTP spans at least once, as reported by OpenTelemetry. Useful when running a guarded rollout.
Average request latency (OpenTelemetry) `otel.http.latency`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : Measures the average request latency, as reported by OpenTelemetry. Useful when running a guarded rollout. For best results, use a ‘request’ randomization unit and send ‘request’ contexts.
P95 request latency (OpenTelemetry) `otel.http.latency`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P95
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : Measures the 95th percentile request latency, as reported by OpenTelemetry. For many applications, this represents the experience for most requests. You can adjust the percentile to fit your application’s needs. Useful when running a guarded rollout. For best results, use a ‘request’ randomization unit and send ‘request’ contexts.
P99 request latency (OpenTelemetry) `otel.http.latency`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: P99
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Description** : Measures the 99th percentile request latency, as reported by OpenTelemetry. For many applications, this represents the worst-case experiences. You can adjust the percentile to fit your application’s needs. Useful when running a guarded rollout. For best results, use a ‘request’ randomization unit and send ‘request’ contexts.
Per-route HTTP request latency (OpenTelemetry) `http.latency;method={http.request.method};route={http.route}`
**Metric kind** : Custom numeric
**Suggested randomization unit** : Request
**Definition** :
 * Measurement method: Value/size
 * Unit aggregation method: Average
 * Analysis method: Average
 * Success criterion: Lower is better
 * Units without events: Exclude units that did not send any events
**Examples** :
 * `http.latency;method=GET;route=/api/v2/flags`
 * `http.latency;method=PATCH;route=/api/v2/flags/{id}`
[![Logo](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/a8964c2c365fb94c416a0e31ff873d21ce0c3cbf40142e7e66cce5ae08a093af/assets/logo-dark.svg)![Logo](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/a8964c2c365fb94c416a0e31ff873d21ce0c3cbf40142e7e66cce5ae08a093af/assets/logo-dark.svg)](/docs/home)
LaunchDarkly docs
LaunchDarkly docs
LaunchDarkly docs
LaunchDarkly docs