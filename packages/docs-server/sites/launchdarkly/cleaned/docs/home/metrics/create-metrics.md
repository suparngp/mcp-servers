`/`
[Product docs](/docs/home)[Guides](/docs/guides)[SDKs](/docs/sdk)[Integrations](/docs/integrations)[API docs](/docs/api)[Tutorials](/docs/tutorials)[Flagship Blog](/docs/blog)
 * Getting started
 * [Overview](/docs/home)
 * [Launch Insights](/docs/home/getting-started/launch-insights)
 * [LaunchDarkly architecture](/docs/home/getting-started/architecture)
 * [LaunchDarkly vocabulary](/docs/home/getting-started/vocabulary)
 * Feature flags and AI Configs
 * [Create flags](/docs/home/flags/create)
 * [Target with flags](/docs/home/flags/target)
 * [Flag templates](/docs/home/flags/templates)
 * [Manage flags](/docs/home/flags/manage)
 * [Code references](/docs/home/flags/code-references)
 * [AI Configs](/docs/home/ai-configs)
 * [Contexts](/docs/home/flags/contexts)
 * [Segments](/docs/home/flags/segments)
 * Releases
 * [Releasing features with LaunchDarkly](/docs/home/releases/releasing)
 * [Release policies](/docs/home/releases/release-policies)
 * [Percentage rollouts](/docs/home/releases/percentage-rollouts)
 * [Progressive rollouts](/docs/home/releases/progressive-rollouts)
 * [Guarded rollouts](/docs/home/releases/guarded-rollouts)
 * [Feature monitoring](/docs/home/releases/feature-monitoring)
 * [Release pipelines](/docs/home/releases/release-pipelines)
 * [Engineering insights](/docs/home/releases/eng-insights)
 * [Release management tools](/docs/home/releases/release-management)
 * [Applications and app versions](/docs/home/releases/apps-and-app-versions)
 * [Change history](/docs/home/releases/change-history)
 * Observability
 * [Observability](/docs/home/observability)
 * [Session replay](/docs/home/observability/session-replay)
 * [Error monitoring](/docs/home/observability/errors)
 * [Logs](/docs/home/observability/logs)
 * [Traces](/docs/home/observability/traces)
 * [LLM observability](/docs/home/observability/llm-observability)
 * [Alerts](/docs/home/observability/alerts)
 * [Dashboards](/docs/home/observability/dashboards)
 * [Search specification](/docs/home/observability/search)
 * [Observability settings](/docs/home/observability/settings)
 * [Vega](/docs/home/observability/vega)
 * Product analytics
 * [Product analytics](/docs/home/product-analytics)
 * [Setting up product analytics](/docs/home/product-analytics/setup)
 * [Using product analytics charts](/docs/home/product-analytics/chart)
 * Experimentation
 * [Experimentation](/docs/home/experimentation)
 * [Creating experiments](/docs/home/experimentation/create)
 * [Managing experiments](/docs/home/experimentation/manage)
 * [Analyzing experiments](/docs/home/experimentation/analyze)
 * [Experimentation and metric events](/docs/home/experimentation/events)
 * [Multi-armed bandits](/docs/home/multi-armed-bandits)
 * [Holdouts](/docs/home/holdouts)
 * Metrics
 * [Metrics](/docs/home/metrics)
 * [Metric groups](/docs/home/metrics/metric-groups)
 * [Autogenerated metrics](/docs/home/metrics/autogen-metrics)
 * [Metric impact](/docs/home/metrics/metric-impact)
 * [Metric events](/docs/home/metrics/metric-events)
 * Warehouse native
 * [Warehouse native Experimentation](/docs/home/warehouse-native)
 * [Warehouse native metrics](/docs/home/warehouse-native/metrics)
 * [Creating warehouse native experiments](/docs/home/warehouse-native/creating)
 * Infrastructure
 * [Connect apps and services to LaunchDarkly](/docs/home/infrastructure/apps)
 * [LaunchDarkly in China and Pakistan](/docs/home/infrastructure/china)
 * [LaunchDarkly in the European Union (EU)](/docs/home/infrastructure/eu)
 * [LaunchDarkly in federal environments](/docs/home/infrastructure/federal)
 * [Public IP list](/docs/home/infrastructure/ip-list)
 * Your account
 * [Projects](/docs/home/account/project)
 * [Views](/docs/home/account/views)
 * [Environments](/docs/home/account/environment)
 * [Tags](/docs/home/account/tags)
 * [Teams](/docs/home/account/teams)
 * [Members](/docs/home/account/members)
 * [Roles](/docs/home/account/roles)
 * [Account security](/docs/home/account/secure)
 * [Billing and usage](/docs/home/account/billing)
 * [Changelog](/docs/home/changelog)
[Sign in](/)[Sign up](https://app.launchdarkly.com/signup)
On this page
 * [Overview](#overview)
 * [Choose a metric type](#choose-a-metric-type)
 * [Create metrics](#create-metrics)
 * [Preview event data](#preview-event-data)
 * [Availability](#availability)
 * [Preview contents](#preview-contents)
 * [Preview states](#preview-states)
 * [Example](#example)
 * [Edit metrics](#edit-metrics)
 * [Archive metrics](#archive-metrics)
 * [View metric details](#view-metric-details)
 * [Details tab](#details-tab)
 * [Impact tab](#impact-tab)
 * [Activity tab](#activity-tab)
 * [Sidebar information](#sidebar-information)
 * [Filter metrics](#filter-metrics)
 * [Delete metrics](#delete-metrics)
## Overview
This topic explains how to create, edit, archive, and delete metrics, and how to select which metric type to use with LaunchDarkly features, such as experiments and guarded rollouts.
When you create a metric, LaunchDarkly provides a data preview after you select an event key. Data previews give you immediate visibility into the events behind your metric so you can confirm that the right data is flowing, that filters are applied correctly, and that your aggregation method produces meaningful results. This reduces risk during metric creation and helps your team configure metrics you can trust more quickly, enabling confident experiments and rollouts.
## Choose a metric type
You should choose a metric type that correctly measures the effect of a change on your customers or codebase. If you are unsure of what metric type to use, it may be helpful to begin by determining what kind of data you are trying to measure. For examples of common metrics and how to configure them, read [Example metrics](/docs/guides/metrics/example-metrics).
This table includes examples of different kinds of data you can measure with different metric types and common randomization unit context kind mappings:
Metric type | Example uses | Example randomization unit 
---|---|--- 
Clicked or tapped conversion | How often do customers click a “Save” button? 
How many times do customers click on a link? 
When is the best point during a process to display a sign-up invitation? | `user` 
Custom conversion binary | Do customer searches call a particular service? 
Do customer payments succeed? 
Do customers contact customer service within a set period of time? 
Do customers renew their contract within 30 days? 
Does this process generate an error? | `user` 
`organization` 
Custom conversion count | How many purchases did a customer make? 
How many times per quarter do customers contact Support? | `user` 
`organization` 
Custom numeric | How much do customers spend per transaction in my store? 
How much do customers spend in total? 
How many items do customers purchase per transaction? 
How many items do customers purchase total? 
How much time do customers spend on a page? 
How long does it take for a server to respond to a request? 
How long until the time to first byte (TTFB)? | `user` 
`guest` 
`request` 
Page viewed conversion | How many times do end users view a blog post? | `user` 
When you create a metric, you must decide how you want to handle its metric and unit analysis. To learn more, read [Metric analysis](/docs/home/metrics/metric-analysis).
## Create metrics
Click the following links to learn how to create each metric type:
 * [Clicked or tapped conversion metrics](/docs/home/metrics/click)
 * [Custom conversion binary metrics](/docs/home/metrics/custom)
 * [Custom conversion count metrics](/docs/home/metrics/custom-count)
 * [Custom numeric metrics](/docs/home/metrics/custom-numeric)
 * [Page viewed conversion metrics](/docs/home/metrics/pageview)
## Preview event data
Metric data previews let you validate your metric configuration by showing recent event samples as you create or edit a custom metric. This section explains where previews are available, what they contain, and the states you may encounter.
### Availability
Previews are available in two places:
 * In the **Create metric** dialog for custom metrics.
 * In the **Metric details** tab for custom metrics if LaunchDarkly has received recent event data.
Previews are not available for clicked or tapped metrics or for page viewed metrics.
When there is no event data:
 * In the **Create metric** dialog, the preview displays “No event data available to preview” and includes a [Learn more](/docs/home/metrics/view-incoming-events) link.
 * In the **Metric details** tab, the preview component does not appear.
### Preview contents
Previews display a table with up to five of the most recent events LaunchDarkly received for the selected **Event key**. Each row displays:
 * Timestamp: when the event occurred
 * Context kinds: such as user or organization keys
 * Event properties: the event JSON, truncated in the table. You can click the truncated version or expand the row to view the full JSON and copy it.
![Event data preview with recent events in the Create metric dialog.](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/10df3d8911e0f83e9d92bafcbc1fdf9b5788c1a90d0941142dd1aa892d3a4466/assets/images/__toPlaywright_newIA/metric-create-event-preview.png)
Event data preview with recent events in the Create metric dialog.
### Preview states
The data preview can display different states depending on the event data available:
 * Recent events shown: displays rows from the five most recent records.
 * No recent events: displays “No event data available to preview.” You can still create the metric.
 * Unable to load data: displays an error message if LaunchDarkly cannot retrieve data.
### Example
Consider a custom numeric metric that measures purchase amount:
 1. In the **Event key** field, select `purchaseCompleted`.
 2. The preview displays the five most recent purchase events, including “Timestamp,” “Context kinds,” and “Event properties.”
 3. Expand a row to view the full event details and copy them if needed.
 4. The health check confirms that the event has been received recently and that all randomization units have events in the last 14 days.
![Event data preview with recent events in the Metric details tab.](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/f4914162d9c9daa0c066939dbb4b2bfc8434ef64b63808ee23a7e85416a87365/assets/images/__toPlaywright_newIA/metric-create-event-preview-example.png)
Event data preview with recent events in the Metric details tab.
This confirms that your instrumentation is correct and that your metric definition matches your measurement goals so you can connect it to an experiment or rollout with confidence.
##### About event data previews
Data previews use the same event data source as the [Event explorer](/docs/home/metrics/view-incoming-events). For a complete view of event history and payloads, use the event explorer.
## Edit metrics
You can edit all of an existing metric’s settings except for its metric kind and metric key.
To edit a metric:
 1. Navigate to the **Metrics** list.
 2. Click the name of the metric you want to edit. The metric details screen opens.
 3. Click the **pencil** icon in the right sidebar next to the field you want to edit. The “Edit metric” dialog appears.
 4. Make the edits you want and click **Save metric**.
![](https://fern-image-hosting.s3.us-east-1.amazonaws.com/launchdarkly/openapi-logo.svg)
You can also use the REST API: [Update metric](/docs/api/metrics/patch-metric)
## Archive metrics
Archiving a metric removes it from the metrics list, dashboards, and metric selectors, while preserving its definition and historical results. Archiving helps reduce clutter and maintain a clean workspace during guarded rollouts and experiments.
Archiving a metric creates a new version. This version reflects the archived state and preserves earlier versions for accurate experiment analysis and audit history. You can view a metric’s current and previous versions on its details page, each reflecting how the metric was configured when it was used.
You can archive a metric unless it is currently used in an active experiment, guarded rollout, or metric group. If the metric is in use, LaunchDarkly disables the archive option and displays a list of the connections.
To archive a metric:
 1. Navigate to the **Metrics** list.
 2. Next to the name of the metric you want to archive, click the **three-dot** overflow menu.
 3. Click **Archive metric**. A confirmation dialog appears that lists the number of experiments, guarded rollouts, and metric groups the metric is connected to.
 4. Click **Archive**.
By default, LaunchDarkly hides archived metrics from the metrics list, experiment setup screens, and metric selection menus. To view them, turn on the **Show archived** filter in the metrics list.
You can restore an archived metric at any time. When you restore a metric, it returns to active use and reappears in the metrics list, metric selectors, and dashboards.
To restore an archived metric:
 1. Navigate to the **Metrics** list.
 2. Turn on the **Show archived** filter.
 3. Next to the name of the metric you want to restore, click the **three-dot** overflow menu.
 4. Click **Restore**. A confirmation dialog appears.
 5. Click **Restore**.
![](https://fern-image-hosting.s3.us-east-1.amazonaws.com/launchdarkly/openapi-logo.svg)
You can also use the REST API: [Update metric](/docs/api/metrics/patch-metric). To archive or restore a metric, replace the `archived` field with `true` or `false`.
LaunchDarkly automatically sets the `archivedAt` timestamp when you archive a metric and clears it when you restore it. You cannot set or modify this field manually.
To archive or restore a metric, your role must include the `updateArchived` action for the metric resource.
## View metric details
After you create a metric, you can view its configuration, connections, and recent activity from the metric details page.
To open a metric:
 1. Navigate to the **Metrics** list.
 2. Click the name of the metric you want to view.
The metric details page includes three tabs and a right-hand sidebar that summarize all available information about the metric.
### Details tab
The **Details** tab displays configuration fields such as event key, metric type, definition, and success criteria. It also shows the **Connections** section, which lists any experiments, guarded rollouts, or metric groups using the metric.
To learn more about metric definition options, read [Metric analysis](/docs/home/metrics/metric-analysis).
### Impact tab
The **Impact** tab lists the experiments that include the metric and shows current effect sizes, variation performance, and experiment status.
### Activity tab
The **Activity** tab shows the most recent events associated with the metric, including timestamp, context key, and value. This helps you verify that your SDK instrumentation is working correctly. To learn more, read [Metric events](/docs/home/metrics/metric-events#metric-event-activity).
### Sidebar information
The sidebar displays additional metadata about the metric, including:
 * Description
 * Maintainer
 * [Tags](/docs/home/account/tags#metrics)
 * Sources
 * Metric key
##### Event keys and metric keys are different
Sending custom events to LaunchDarkly requires a unique **event key**. You can set the event key to anything you want. The metric key is generated automatically and is used only to identify the metric in API calls. To learn more, read [Metric events](/docs/home/metrics/metric-events#event-keys).
![A metric’s page with details, impact, and activity.](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/f0b7568b4a5c5356abff966d25f58efa5ed0cc7c292f93b81aabc6f2618269cf/assets/images/__toPlaywright_newIA/metric-page.png)
The metric details page with tabs for Details, Impact, and Activity.
To analyze a metric’s results, read [Metric analysis](/docs/home/metrics/metric-analysis). To view or filter events associated with a metric, read [Metric events](/docs/home/metrics/metric-events).
## Filter metrics
After you create a metric, you can optionally configure [metric event filters](/docs/home/metrics/event-filters) to control which events are included in its analysis. This lets you focus the metric on specific context attributes or event properties, such as events where the `variationKey` is `treatment` or the `country` context attribute is `CA`.
To learn more, read [Filtering custom metric events](/docs/home/metrics/event-filters).
## Delete metrics
Deleting a metric is irreversible. You cannot recover a metric after you delete it.
LaunchDarkly recommends archiving metrics instead of deleting them. Archiving preserves the metric’s historical data and audit trail, and removes it from selection menus and dashboards by default.
You can only delete a metric if:
 * It is already archived
 * It has **never** been used in any experiments or guarded releases
To delete a metric:
 1. Navigate to the **Metrics** list.
 2. Turn on the **Show archived** filter.
 3. Click the name of the archived metric you want to delete. The metric details screen opens.
 4. If the metric has never been used in an experiment or guarded release, click **Delete metric**. A confirmation dialog appears.
 5. Click **Delete metric**.
![](https://fern-image-hosting.s3.us-east-1.amazonaws.com/launchdarkly/openapi-logo.svg)
You can also use the REST API: [Delete metric](/docs/api/metrics/delete-metric)
[![Logo](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/a8964c2c365fb94c416a0e31ff873d21ce0c3cbf40142e7e66cce5ae08a093af/assets/logo-dark.svg)![Logo](https://files.buildwithfern.com/https://launchdarkly.docs.buildwithfern.com/docs/a8964c2c365fb94c416a0e31ff873d21ce0c3cbf40142e7e66cce5ae08a093af/assets/logo-dark.svg)](/docs/home)
LaunchDarkly docs
LaunchDarkly docs
LaunchDarkly docs
LaunchDarkly docs